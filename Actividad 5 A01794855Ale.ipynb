{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c80b511-6832-41e8-83cb-09faa3389fb8",
   "metadata": {},
   "source": [
    "# Actividad 5: Visualización de Resultados y Variabilidad con Big Data (PySpark)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Proceso de validación cruzada y justificación de k\n",
    "\n",
    "En esta sección se define el proceso de validación cruzada para evaluar la variabilidad y precisión de los modelos de aprendizaje automático aplicados al conjunto de datos de reseñas de libros.  \n",
    "Partiendo de la muestra estratificada M (derivada de variables de caracterización \n",
    "de la población y construida en la Actividad 4), se selecciona la técnica de validación cruzada k-fold.\n",
    "\n",
    "**Justificación del valor de k:**  \n",
    "El valor de k determina el número de particiones (folds) en los que se divide la muestra M.  \n",
    "Seleccionar un k demasiado pequeño, las divisiones no reflejan bien los datos ; si es muy grande, el procesamiento se vuelve muy costoso computacionalmente sobre todo en análisis de grandes volumenes de datos.\n",
    "En este caso, optamos por un valor de k=5, ya que permite que cada fold contenga una cantidad suficiente de muestras de todos los estratos, logrando representatividad y eficiencia.\n",
    "Esta elección se basa en la distribución de las clases y el tamaño de la muestra, permitiendo que la validación represente correctamente la diversidad del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6278053-2ad1-49b3-b09f-df847307dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Inicio de sesión en Spark e importación de librerías \n",
    "# Importar PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count, regexp_extract, rand, row_number, floor\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# ML y transformación de datos\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198cf6e0-4ec3-40c8-ab22-9adf0443f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession iniciada correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Iniciar sesión Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('BooksRatingDemo') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"SparkSession iniciada correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cbd26-ac63-4191-afc1-828ebb74edc3",
   "metadata": {},
   "source": [
    "## 2. Construcción de los k-folds estratificados\n",
    "\n",
    "Esta sección implementa la creación de los k-folds siguiendo el enfoque de muestreo estratificado planteado en la Actividad 3.  \n",
    "Cada fold se construye de manera que mantenga la proporción de las clases y estratos presentes en la muestra M. Esto ayuda a que cada grupo sea representativo y evita errores en el análisis.\n",
    "\n",
    "Luego, se muestra el código que realiza esta partición y presentan los resultados para confirmar que los datos mantienen el equilibrio esperado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d924c013-1ba7-4175-a64a-269509cfc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y limpiar la muestra M \n",
    "df = spark.read.option('header', 'true').csv('Books_rating.csv')\n",
    "df = df.limit(5000)\n",
    "df = df.filter(\n",
    "    (col(\"review/score\").isNotNull()) &\n",
    "    (col(\"review/helpfulness\").isNotNull()) &\n",
    "    (col(\"user_id\").isNotNull())\n",
    ")\n",
    "df = df.withColumn(\"Helpfulness_num_raw\", regexp_extract(col(\"review/helpfulness\"), r'^(\\d+)', 1))\n",
    "df = df.filter((col(\"Helpfulness_num_raw\").isNotNull()) & (col(\"Helpfulness_num_raw\") != \"\"))\n",
    "df = df.withColumn(\"Helpfulness_num\", col(\"Helpfulness_num_raw\").cast(IntegerType()))\n",
    "df = df.withColumn(\"Score_num\", col(\"review/score\").cast(FloatType()))\n",
    "df = df.filter(col(\"Score_num\").isNotNull())\n",
    "df = df.drop(\"Helpfulness_num_raw\")\n",
    "df = df.withColumn(\"score_group\", when(col(\"Score_num\") >= 4, \"Alta\").otherwise(\"Baja\"))\n",
    "df = df.withColumn(\"helpfulness_group\", when(col(\"Helpfulness_num\") >= 8, \"Alta\").otherwise(\"Baja\"))\n",
    "\n",
    "# Agregar frecuencia de reseñas y categorización de usuario\n",
    "user_reviews = df.groupBy(\"user_id\").agg(count(\"user_id\").alias(\"review_count\"))\n",
    "df = df.join(user_reviews, on=\"user_id\", how=\"left\")\n",
    "df = df.withColumn(\n",
    "    \"user_group_detailed\",\n",
    "    when(col(\"review_count\") >= 20, \"20+ reseñas\")\n",
    "    .when((col(\"review_count\") >= 10) & (col(\"review_count\") < 20), \"10-19 reseñas\")\n",
    "    .when((col(\"review_count\") >= 5) & (col(\"review_count\") < 10), \"5-9 reseñas\")\n",
    "    .when((col(\"review_count\") >= 2) & (col(\"review_count\") < 5), \"2-4 reseñas\")\n",
    "    .otherwise(\"1 reseña\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d857888-c917-448a-b45a-3bee4a17867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------+-------------------------------------------------------+---------+---------------+-------------------+-----------+-----------------+\n",
      "|user_id       |review/helpfulness|review/score|review/summary                                         |Score_num|Helpfulness_num|user_group_detailed|score_group|helpfulness_group|\n",
      "+--------------+------------------+------------+-------------------------------------------------------+---------+---------------+-------------------+-----------+-----------------+\n",
      "|A1D2C0WDCSHUWZ|12/13             |5.0         |Fantasy classic                                        |5.0      |12             |5-9 reseñas        |Alta       |Alta             |\n",
      "|AFVQZQ8PW0L   |11/16             |5.0         |entertaining unique look at the Greek culture          |5.0      |11             |5-9 reseñas        |Alta       |Alta             |\n",
      "|A3M174IC0VXOS2|8/8               |5.0         |TREVOR, A COMMANDER OF LUMINOUS PROSE                  |5.0      |8              |5-9 reseñas        |Alta       |Alta             |\n",
      "|A1D2C0WDCSHUWZ|36/40             |4.0         |Entertaining tale of old New Orleans                   |4.0      |36             |5-9 reseñas        |Alta       |Alta             |\n",
      "|A3M174IC0VXOS2|11/12             |5.0         |AN EXPLOSIVE READING OF A SUSPENSE LADEN POWERHOUSE    |5.0      |11             |5-9 reseñas        |Alta       |Alta             |\n",
      "|AFVQZQ8PW0L   |8/8               |5.0         |delightful romantic romp                               |5.0      |8              |5-9 reseñas        |Alta       |Alta             |\n",
      "|A14OJS0VWMOSWO|16/16             |5.0         |A unique, off-the-beaten-path travel guide and planner.|5.0      |16             |5-9 reseñas        |Alta       |Alta             |\n",
      "|A14OJS0VWMOSWO|38/38             |5.0         |A timeless and memorable anthology                     |5.0      |38             |5-9 reseñas        |Alta       |Alta             |\n",
      "|A14OJS0VWMOSWO|16/17             |5.0         |Filled from cover to cover with practical guidance     |5.0      |16             |5-9 reseñas        |Alta       |Alta             |\n",
      "|A1L43KWWR05PCS|13/15             |4.0         |A LONG DAY'S JOURNEY INTO NIGHT...                     |4.0      |13             |2-4 reseñas        |Alta       |Alta             |\n",
      "+--------------+------------------+------------+-------------------------------------------------------+---------+---------------+-------------------+-----------+-----------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Construcción de muestra M estratificada\n",
    "from itertools import product\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "\n",
    "selected_columns = [\n",
    "    \"user_id\", \"review/helpfulness\", \"review/score\", \"review/summary\",\n",
    "    \"Score_num\", \"Helpfulness_num\", \"user_group_detailed\", \"score_group\", \"helpfulness_group\"\n",
    "]\n",
    "muestras = []\n",
    "for s, h in product([\"Alta\", \"Baja\"], repeat=2):\n",
    "    for u in [\"20+ reseñas\", \"10-19 reseñas\", \"5-9 reseñas\", \"2-4 reseñas\", \"1 reseña\"]:\n",
    "        subset = df.filter(\n",
    "            (col(\"score_group\") == s) &\n",
    "            (col(\"helpfulness_group\") == h) &\n",
    "            (col(\"user_group_detailed\") == u)\n",
    "        )\n",
    "        muestra = subset.orderBy(F.rand()).select(*selected_columns).limit(30)\n",
    "        muestras.append(muestra)\n",
    "M = reduce(lambda a, b: a.unionByName(b), muestras)\n",
    "M.cache()\n",
    "M.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8f7b38-b0d5-4730-9e5c-97a3c1f37fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+\n",
      "|fold|score_group|count|\n",
      "+----+-----------+-----+\n",
      "|   0|       Alta|   35|\n",
      "|   0|       Baja|   17|\n",
      "|   1|       Alta|   29|\n",
      "|   1|       Baja|   23|\n",
      "|   2|       Alta|   35|\n",
      "|   2|       Baja|   17|\n",
      "|   3|       Alta|   29|\n",
      "|   3|       Baja|   22|\n",
      "|   4|       Alta|   31|\n",
      "|   4|       Baja|   20|\n",
      "+----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construcción de los k-folds\n",
    "k = 5\n",
    "window = Window.orderBy(rand())\n",
    "M = M.withColumn(\"row_num\", row_number().over(window))\n",
    "M = M.withColumn(\"fold\", ((M.row_num - 1) % k))\n",
    "M.groupBy(\"fold\", \"score_group\").count().orderBy(\"fold\", \"score_group\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2a682-3567-49f4-b83b-87f0fead892c",
   "metadata": {},
   "source": [
    "## 3. Fase de entrenamiento (“Experimentación”)\n",
    "\n",
    "En esta parte se lleva a cabo el entrenamiento del modelo seleccionado (por ejemplo, Random Forest, el mejor modelo identificado en la Actividad 4) para entrenarlo con los fols o grupo de datos creados antes.\n",
    "Para cada fold se realiza el proceso de entrenamiento y validación, registrando las métricas de desempeño relevantes (accuracy, F1-score, precisión, recall, etc.).\n",
    "\n",
    "El objetivo es ver qué tan bien funciona el modelo en distintas condiciones y medir la variablidiad de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109109a-e210-476e-9298-ad06dbf97f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexado de variables categóricas\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"score_group\", outputCol=\"score_index\"),\n",
    "    StringIndexer(inputCol=\"user_group_detailed\", outputCol=\"user_group_index\"),\n",
    "    StringIndexer(inputCol=\"helpfulness_group\", outputCol=\"helpfulness_index\")\n",
    "]\n",
    "for idx in indexers:\n",
    "    M = idx.fit(M).transform(M)\n",
    "\n",
    "# Ensamblado de features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Helpfulness_num\", \"user_group_index\", \"helpfulness_index\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "M = assembler.transform(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07afaf-b55f-424c-83c3-99765d7eaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada y recolección de métricas\n",
    "metrics = []\n",
    "for fold in range(k):\n",
    "    train_df = M.filter(M.fold != fold)\n",
    "    test_df = M.filter(M.fold == fold)\n",
    "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"score_index\", seed=42)\n",
    "    model = rf.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"score_index\", predictionCol=\"prediction\")\n",
    "    fold_metrics = {\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}),\n",
    "        \"f1\": evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}),\n",
    "        \"precision\": evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"}),\n",
    "        \"recall\": evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"}),\n",
    "    }\n",
    "    metrics.append(fold_metrics)\n",
    "\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9ec14-d79e-4971-a56c-5f892d789031",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf9340f-45de-4277-a357-323f6274a724",
   "metadata": {},
   "source": [
    "## 4. Resultados\n",
    "\n",
    "En esta sección se presentan los datos obtenidos en el experimento, destacando gráficos que muestran el desempeño del modelo y como estan distribuidos los datos.\n",
    "\n",
    "### 4.1 Estadísticas generales y distribución\n",
    "\n",
    "Se incluyen estadisticas generales y la distribución de los grupos de datos, los gráficos ayudan a detectar posibles errores o desequilibrios en el muestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83140fdf-0613-4319-86b7-822fc5b38383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de la muestra M\n",
    "M_pd = M.select(\"Helpfulness_num\", \"Score_num\", \"user_group_detailed\", \"score_group\", \"helpfulness_group\").toPandas()\n",
    "display(M_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c8147-d960-4407-b233-19da9f091ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por score_group\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"score_group\", data=M_pd)\n",
    "plt.title(\"Distribución de score_group en muestra M\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741a437-626f-4b87-bba2-841ae7fb04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por helpfulness_group\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"helpfulness_group\", data=M_pd)\n",
    "plt.title(\"Distribución de helpfulness_group en muestra M\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796de88-cd7c-46b1-bbed-fe95b7a782a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución por user_group_detailed\n",
    "plt.figure(figsize=(9,4))\n",
    "sns.countplot(x=\"user_group_detailed\", data=M_pd, order=M_pd[\"user_group_detailed\"].value_counts().index)\n",
    "plt.title(\"Distribución de user_group_detailed en muestra M\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71612db-66c9-4ce5-a496-e248824bda89",
   "metadata": {},
   "source": [
    "### 4.2 Métricas por fold\n",
    "Se visualizan gráficos con los resultados del modelo, como precisión y rendimiento. Estos ayudan a análizar qué tan estable y variable es el modelo en distintos grupos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99854b6-577d-42ce-970c-a7d704b0c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=metrics_df[['accuracy','f1','precision','recall']])\n",
    "plt.title(\"Boxplot de métricas por fold\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axs[0, 0].plot(metrics_df['fold'], metrics_df['accuracy'], marker='o', color='b')\n",
    "axs[0, 0].set_title('Accuracy por Fold')\n",
    "axs[0, 0].set_xlabel('Fold'); axs[0, 0].set_ylabel('Accuracy'); axs[0, 0].grid(True)\n",
    "\n",
    "axs[0, 1].plot(metrics_df['fold'], metrics_df['f1'], marker='o', color='g')\n",
    "axs[0, 1].set_title('F1 Score por Fold')\n",
    "axs[0, 1].set_xlabel('Fold'); axs[0, 1].set_ylabel('F1 Score'); axs[0, 1].grid(True)\n",
    "\n",
    "axs[1, 0].plot(metrics_df['fold'], metrics_df['precision'], marker='o', color='r')\n",
    "axs[1, 0].set_title('Precisión por Fold')\n",
    "axs[1, 0].set_xlabel('Fold'); axs[1, 0].set_ylabel('Precisión'); axs[1, 0].grid(True)\n",
    "\n",
    "axs[1, 1].plot(metrics_df['fold'], metrics_df['recall'], marker='o', color='purple')\n",
    "axs[1, 1].set_title('Recall por Fold')\n",
    "axs[1, 1].set_xlabel('Fold'); axs[1, 1].set_ylabel('Recall'); axs[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(metrics_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea1ef0-3bc2-4fa2-bfda-f5dcff20c381",
   "metadata": {},
   "source": [
    "### 4.3 Matriz de confusión\n",
    "\n",
    "Se muestra una matriz de confusión que resume el desempeño del modelo, destacando aciertos y errores en la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f95df-e09f-45c7-a35e-f0e964efc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673549b-65d7-400a-9a3b-87bb9a54ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Matriz de confusión\n",
    "\n",
    "# Importar sklearn para matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Se toma el ultimo fold como ejemplo para promediar \n",
    "pred_fold = model.transform(test_df)\n",
    "y_true = pred_fold.select(\"score_index\").toPandas().astype(int)\n",
    "y_pred = pred_fold.select(\"prediction\").toPandas().astype(int)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matriz de confusión Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70221b34-75c6-4b95-bb89-448d1ad7e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa de calor \n",
    "# Heatmap de correlación\n",
    "corr = M_pd[[\"Helpfulness_num\",\"Score_num\"]].corr()\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(corr, annot=True, cmap='crest')\n",
    "plt.title('Matriz de correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2bea7b-9a22-4597-8593-2f445261d101",
   "metadata": {},
   "source": [
    "## 5. Discusión de Resultados y Conclusiones\n",
    "\n",
    "**Robustez y representatividad de la muestra:**  \n",
    "La muestra M fue construida mediante un muestreo estratificado, para garantizar que todos los grupos importantes estuvieran bien representados. Esto ayuda a obtener resultados confiables y equilibrados en cada etapa del análisis.\n",
    "\n",
    "**Desempeño del modelo y matriz de confusión:**  \n",
    "El modelo Random Forest se entrenó y evaluó mediante validación cruzada k-fold, permitiendo medir la variabilidad y estabilidad de las métricas de desempeño.  \n",
    "La matriz de confusión presentada muestra la cantidad de aciertos y errores en cada clase (por ejemplo, `Alta` vs `Baja`) para el fold evaluado. \n",
    "\n",
    "**Interpretación de los resultados:**  \n",
    "- Si la mayoría de los valores estan en la diagonal,el modelo distingue bien las clases.\n",
    "- Si hay errores fuera de la diagonal, puede necesitar mejoras, como más datos o ajustes de parámetros. \n",
    "- Un buen desempeño en la matriz de confusión, junto con métricas de accuracy, F1 y recall estables entre los folds sigifica que el modelo es confiable y sin sesgos.\n",
    "\n",
    "**Variabilidad y significancia:**  \n",
    "La validación cruzada ayuda a estimar qué tan consistentes serán los resultados si aplicamos el modelo a nuevos datos. Si las métricas son estables , el modelo es sólido y los resultados no son producto del  azar.\n",
    "\n",
    "**Conclusión final:**  \n",
    "El análisis de las calificaciones de libros, realizado con validación cruzada y un modelo Random Forest, permitió evaluar qué tan bien se puede predecir si una reseña corresponde a una calificación alta o baja. La matriz de confusión fue clave para interpretar los resultados en cada etapa de validación.\n",
    "Los resultados muestran que el modelo funciona bien al diferenciar reseñas con calificaciones altas y bajas. La mayoría de las predicciones fueron correctas, pero aún hay algunos casos en los que el modelo se confunde, sobre todo cuando las características de las reseñas no ofrecen información clara para distinguirlas.\n",
    "Además, al analizar métricas como accuracy, F1, precisión y recall, se observó que el rendimiento del modelo es constante y no varía significativamente entre los distintos pliegues de validación. Esto indica que el modelo generaliza bien y no está sobreajustado.\n",
    "En resumen, el proceso de análisis utilizado—desde la limpieza de datos hasta la visualización de resultados—permitió desarrollar un modelo sólido para predecir la calificación de las reseñas de libros. La matriz de confusión no solo ayudó a entender los aciertos y errores del modelo, sino que también reveló patrones que podrían servir para mejorar futuras versiones del análisis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
